---
title: "Cheese Succession (Brooke paper)"
author: "Collin Edwards"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## libraries

```{r}
library(here)
library(tidyverse)
library(deSolve)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(viridis)
library(pander)
library(car)
library(lme4)
```


## Functions

Sometimes it's helpful to define a function for code we want to re-use a lot. The key function like that for me is something I call `gfig_saver`, which makes saving ggplot figures systematic.

```{r gfig_saver}
# function for saving ggplot figures and metadata. As fig_starter (which is for base graphics), except that saving ggfigures is inherently cleaner, as you are not feeding commands to an open graphics device

gfig_saver=function(gfig, #object to be saved
                    filename, #name of figure file to save as WITHOUT SUFFIX
                    description, #vector of strings, each will be put in its own line of meta file
                    ##  Note: generating file is defined in the function, date and time is automatically added.
                    ##default figure info:
                    width=12,
                    height=8,
                    res=300,
                    units="in",
                    figfold="5_figs" #folder to save figures in
){
  ## save meta file
  cat(c(description,
        "",##easy way to add an extra line to separate description for basic data.
        
        paste("from", knitr::current_input()),
        "RDS file with same name contains ggplot object used to generate this figure.",
        as.character(Sys.time())),
      sep="\n",
      file=here(figfold, paste0(filename,"_meta.txt", sep=""))
  )
  #save figure as jpg (change code here for other figure types)
  ggsave(filename=here(figfold, paste0(filename,".jpg")),
         plot=gfig,
         device="jpeg",
         dpi=res,
         width=width, height=height, units=units
  )
  ggsave(filename=here(figfold, paste0(filename,".pdf")),
         plot=gfig,
         device="pdf",
         dpi=res,
         width=width, height=height, units=units
  )
  #save ggplot object as RDS file, for easy manipulation later
  saveRDS(object = gfig, file=here(figfold, paste0(filename,".RDS")))
}
```


```{r}
theme.mine=theme(plot.title = element_text(face="bold", size=24),
                 text=element_text(size=rel(4.5)),
                 legend.text=element_text(size=rel(2))
)
```


## Purpose

The goal is to determine whether data from single-species and pairwise experiments (e.g. at most pairwise interactions) in Brooke's cheese data can explain the community dynamics from treatments inoculated with a full 7-species community. The manuscript for this project is [here](https://docs.google.com/document/u/1/d/1KIhnJMmHf3wOXv_0DQ9UgcjIVkz1v0FGFiyUVdktreE/edit?ts=608b2425).

## Plan

**The goal:**

Determine if the 7-species community can be predicted/described by pairwise interactions. 

**The problem:**

"Community" is hard to define. With only 4 time points, classical population dynamics approaches are liable to run into issues. Estimating confidence intervals from the standard trajectory-matching approach for fitting population dynamics models is unreasonable, as bootstrapping seems problematic with such little data.

**The solution:**

If we imagine that the system is actually following Lotka-Volterra competition (the simplest competition model), then at least for the 2-species experiments, the populations will eventually reach an equilibrium (which can have one of the populations at size zero). The equilibrium for Lotka Volterra is clearly defined in terms of just carrying capacity and interaction terms (generally denoted with $\alpha$s) that capture either competition or stimulation. Using that knowledge, and assuming that the populations are at equilibrium on day 21, we can estimate the alphas and the carrying capacity from the paired experiments, and see if those predict the final population sizes of the 7-species community.

**A little math background:**

The Lotka-Volterra competition model is defined by a system of Ordinary Differential Equations (ODEs). This is fancy math-speak for some equations that define how the size of the populations changes at any given point in time, based on the current size of the populations. For LV, it's this set of equations:

\[\frac{dx_1}{dt} = r_1x_1\big(1-\big(\frac{x_1 \alpha_{12} x_2}{K_2}\big)\big)\]
\[\frac{dx_2}{dt} = r_2x_2\big(1-\big(\frac{x_2 \alpha_{21} x_1}{K_2}\big)\big)\]

Where 

- $x_i$ is the population size of species $i$, 
- the $r$ parameters correspond to intrinsic growth rates (growth when not competing)
- the $K$ parameters correspond to the carrying capacity in the absence of other species
- $\alpha_{ij}$ is the competition coefficient for species $j$ on species $i$. I like to think of this as a conversion rate - an $\alpha_{ij}$ of 2 means that each individual of species $j$ has the same competition effect on species $i$ as would 2 individuals of species $i$. So big values mean the other species has a strong suppression effect, small values mean a minimal suppression effect. I'm not used to LV with facilitation, but negative alphas mean that one species is helping the other.

There is a lot of really cool math that has gone into things we can discover/prove with ODEs, but we actually don't need most of it right now. If our populations are at equilibrium in our day 21 data, that means the population sizes aren't changing. So there's no rate of change, so $\frac{dx}{dt}$ is 0. If we set the left hand side of each equation to zero, and do a little re-arranging of terms with algebra, we get:

\[x_1 = K_1 - \alpha_{21}  x_2\]
and
\[x_2 = K_2 - \alpha_{12}  x_1\]

Those are actually just a different version of our equation for a straight line,

\[y = mx + b\]

where $y$ and $x$ are the sizes of our two populations

Taking this approach, we can find carrying capacity and interaction terms with linear regression using the single-species and pairwise interaction data (!!). We still face the caveats of our various assumptions (below), but this is suddenly incredibly tractable. Additionally, we can leverage this approach to ask what the 7-species community would look like if it were mostly the result of pariwise interactions, by individually predicting the abundance of each species contingent on the observed abundances of the others, in the form of

\[K_i - \sum_{j\neq i}(\alpha_{ij} x_j)\] 


Some caveats:
First, we're assuming that lotka volterra dynamics do a good job of capturing the key dynamics in the system. Second, we're assuming that populations are at equilibrium on day 21 -- from the data, it looks like they are in some cases, but not in all not in others. Additionally, communities of more than 2 species with lotka volterra competition aren't guaranteed to have an equilibrium at all - they can exhibit non-equilibrium dynamics like periodic cycles through time, or mathematical chaos. 

Looking at the results it certainly looks like we're wrong in making these assumptions, but that we're probably close enough. (Any modeling work will be making some incorrect assumptions - the goal is to make sure they don't impact the aspects of the model/result that we're interested in). My take on all of this is that (a) it doesn't look like there's anything too crazy going on here (no sine-wave type behavior we can see, for example), (b) there's a lot that's unknown in modeling microbial communities, and it seems like the most elaborate things being used right now are Lotka Volterra, so I think we're in fine company, and (c) we have to work with the data we have, and while it's astounding in a lot of ways, we don't have enough time points to effectively do more elaborate modeling of population dynamics. 

One thing to bear in mind is that LV is also often unsuited to capturing mutualisms -- there are some parameter values where both species explode to infinite size even though there's a finite carrying capacity. I don't think that's an issue with our data, but it's something to be aware of. I haven't dug into it a ton, but there has been recent work on how to model community dynamics and coexistence when working with mutualisms. I might need to take a look at that at some point (although again, I think we have a good plan outlined above).

Some anti-caveats

One of the nice things about only working with the stable equilibrium (aside from the math being tractable) is that we're not actually making any assumptions about growth rate or dynamics up to that point. We're just assuming that each species has an equilibrium size that is a linear function of the other species at equilibrium. So if we wanted to, we could actually NOT call this Lotka Volterra competition. Our approach encompasses ANY model with those equilibrium conditions. (But I think we still couch it in terms of LV, because folks are familiar with that). 

# Read in data

```{r}
dat.orig = raw = read.csv(here("1_raw_data",
                               "2018_08_21_Bayley_allPW.csv"))
```

# Approach: Use linear models

If we assume the communities are at equilibrium on day 21, and if their dynamics are defined by lotka volterra dynamics, their abundance is a linear function of the densities of competitors. For the two-species LV model, the equilibrium densities of species 1 and species 2 (denoted $N_1^*$ and $N_2^*$) are defined by

\[N_1^* = K_1 - \alpha_{12}N_2^*\]

and

\[N_2^* = K_2 - \alpha_{21}N_1^*\]


Since we're assuming the populations are at equilibrium, our observations give us $N_1^*$ and $N_2^*$, and we can fit a regression model to estimate $K$ and the $\alpha$ terms. (and we can use the regression framework to estimate our error)

Using our pairwise experiments, we can estimate all parameters for species 1 simultaneously, with

\[N_1^* = K_1 - \alpha_{12}N_2^* - \alpha_{13}N_3^*-\dots\]

Note that when fitting the above model, for any given entry, at most one of the Ns on the right hand side will be non-zero (that is, either the observation comes from a species alone, in which case all other Ns are 0, or it comes from a two-species experiment, in which case ONE other N will be some postitive number, and the rest will be zeros). 

Using this framework, we can fit the data and see how well it predicts the observed 7-species community.

Note two caveats:

* if it doesn't fit the 7-species data well, that suggests either complex interactions OR that one or more of the data sets isn't at equilibrium.
* The error structure is probably pretty complicated, since we're "re-using" the same data to estimate the parameters for multiple species. Elizabeth and I both think this isn't worth worrying about


Update (8/26/21): fitting the data in two step process: first estimate k, then calculate everything else. So estimate k using original data, then for interaction terms fit a no-intercept model after subtracting the carrying capacity.

## Step 1: restructure data 

We need a data frame with a row for each experiment, and a column for the density of each species. 

```{r}
#make empty data frame
#We want to store cfus for each species, 
df.template = 
  dat.mat = setNames(data.frame(matrix(ncol = 2*length(unique(raw$spec))+2, nrow = 0)),
                     c(as.character(unique(raw$spec)), "cond", "rep",paste0("pres.",c(as.character(unique(raw$spec)))))
  )
raw.use = raw %>% 
  filter(day == 21) %>% 
  filter(pH == 5)
#handle the alones
for(cur.spec in unique(raw.use$spec)){
  print(cur.spec)
  dat.cur = raw.use %>% 
    filter(spec == cur.spec) %>% 
    filter(cond == "alone")
  df.fill=as.data.frame(matrix(0, 
                               nrow=nrow(dat.cur),
                               ncol=ncol(dat.mat)))
  names(df.fill) = names(dat.mat)
  df.fill[,cur.spec]=dat.cur$cfus
  df.fill[,"rep"]=dat.cur$rep
  df.fill[,"cond"]="alone"
  df.fill[,paste0("pres.",cur.spec)] = T
  dat.mat = rbind(dat.mat, df.fill)
}

## pairs
spec.vec = as.character(unique(raw.use$spec))

for(i.spec in 1:(length(spec.vec)-1)){
  cur.spec = spec.vec[i.spec]
  for(j.spec in (i.spec+1):length(spec.vec)){
    other.spec = spec.vec[j.spec]
    #get cfus of current species
    dat.cur = raw.use %>% 
      filter(spec == cur.spec) %>% 
      filter(cond == other.spec)
    #get cfus of other species
    dat.other = raw.use %>% 
      filter(spec == other.spec) %>% 
      filter(cond == cur.spec)
    #handle replicate mismatching
    dat.cur = dat.cur[dat.cur$rep %in% dat.other$rep,]
    dat.other = dat.other[dat.other$rep %in% dat.cur$rep,]
    dat.cur=dat.cur[order(dat.cur$rep),]
    dat.other=dat.other[order(dat.other$rep),]
    
    ## The following code is a bunch of sanity checking.
    if(nrow(dat.cur) != nrow(dat.other)){
      stop("dimensions not matching up. investigate")
      # print(paste(cur.spec, other.spec))
      # print("dimensions not matching up. investigate")
    }
    if(any(dat.cur$rep != dat.other$rep)){
      stop("replicates not matching up. investigate")
      # print(paste(cur.spec, other.spec))
      # print("replicates not matching up. investigate")
    }
    df.fill=as.data.frame(matrix(0,
                                 nrow=nrow(dat.cur),
                                 ncol=ncol(dat.mat)))
    names(df.fill) = names(dat.mat)
    df.fill[ , cur.spec] = dat.cur$cfus
    df.fill[ , other.spec] = dat.other$cfus
    df.fill[,"rep"]=dat.cur$rep
    df.fill[,"cond"]="paired-comp"
    df.fill[,paste0("pres.",cur.spec)] = T
    df.fill[,paste0("pres.",other.spec)] = T
    dat.mat = rbind(dat.mat, df.fill)
  }
}
dat.mat$day = 21
dat.mat$pH = 5
names(dat.mat)[names(dat.mat)=="pres.135E"]="pres.X135E"

write.csv(dat.mat, 
          file = here("2_data_wrangling","matrix-form.csv"),
          row.names = FALSE
)
```

Make a data frame to store ALL community prediction data for MSE calculations at the end
```{r}
pred.all = NULL
```


## Fitting

Note that we use carrying capacities calculated from the monocultures.

<!-- ### Testing: fit one species -->

<!-- # ```{r} -->
<!-- library(lme4) -->
<!-- dat.fit = read.csv(file = here("2_data_wrangling","matrix-form.csv")) -->
<!-- #NOTE: R adds a leading X to column names that start with numbers -->

<!-- dat.k = dat.orig %>%  -->
<!--   filter(day==21) %>%  -->
<!--   filter(spec=="BC9") %>%  -->
<!--   filter(cond=="alone") %>%  -->
<!--   filter(pH == 5) -->
<!-- out = lm(cfus ~ 1, data = dat.k ) -->
<!-- k.cur = out$coefficients[[1]] -->
<!-- dat.mod = dat.fit[dat.fit$pres.BC9==1,] -->
<!-- dat.mod$BC9=dat.mod$BC9-k.cur -->
<!-- out = lm(BC9 ~ -1 + BC10 + JB5 + JB7 + X135E + JBC + JB370, -->
<!--          data = dat.mod) -->
<!-- summary(out) -->
<!-- hist(resid(out), breaks=20) -->
<!-- # coefficients(out) -->

<!-- #UPDATED NOTE: upon reflection, the log scale enforces a different relationship between -->
<!-- # individuals, and would NOT capture the L-V model. So we should not do this even from -->
<!-- # a theoretical basis, even ignoring that practically the linear model fit better. -->
<!-- #  -->
<!-- # dat.log=dat.fit -->
<!-- # dat.log[,1:7] = log(dat.log[,1:7]+1) -->
<!-- # #let's try a log transform, because that seems relevant -->
<!-- # out.log = lm(BC9 ~ BC10 + JB5 + JB7 + X135E + JBC + JB370, -->
<!-- #              data = dat.log[dat.log$pres.BC9==1,]) -->
<!-- # hist(resid(out.log), breaks=20) -->
<!-- # #The linear scale appears better, and is simpler to handle. -->
<!-- ``` -->

### Loop over all species
```{r}
dat.fit = read.csv(file = here("2_data_wrangling","matrix-form.csv"))
res.est = NULL
spec.vecfit = unique(raw$spec)
spec.vecfit[spec.vecfit=="135E"] = "X135E"
for(i.spec in 1:length(spec.vec)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  
  ## calculate K
  dat.k = dat.orig 
  dat.k$spec[dat.k$spec=="135E"]="X135E"
  dat.k = dat.k %>% 
    filter(day==21) %>% 
    filter(spec==cur.spec) %>% 
    filter(cond=="alone") %>% 
    filter(pH == 5)
  out.k = lm(cfus ~ 1, data = dat.k )
  k.cur = out.k$coefficients[[1]]
  ## modify the data to ensure we're accounting for k
  ind.use = dat.fit[,paste0("pres.",cur.spec)]==1
  dat.cur = dat.fit[ind.use,]
  dat.cur = dat.cur %>% 
    filter(cond !="alone")
  dat.cur[,cur.spec]=dat.cur[,cur.spec]-k.cur
  #generate formula automatically
  # Note that we are fitting a zero-intercept model, as we have already subtracted out K.
  #
  form = paste0(cur.spec," ~ -1 + ", paste(spec.vecfit[-i.spec], collapse = " + "))
  out.cur = lm(formula(form),
               data = dat.cur)
  cur.df = data.frame(est = c(coefficients(out.k),coefficients(out.cur)),
                      se = c(coef(summary(out.k))[,2], coef(summary(out.cur))[,2]))
  #switch to alphas (for everything but Ks, which are the first entry) by multiplying by -1
  cur.df$est[-1]=-cur.df$est[-1]
  cur.df$spec = cur.spec
  cur.df$name = rownames(cur.df)
  cur.df$pH = 5
  rownames(cur.df)=NULL
  cur.df$name[1] = "K"
  #reorder
  cur.df=cur.df[,c("spec","name","est","se", "pH")]
  res.est = rbind(res.est, cur.df)
}
## and that's our fits
## 
write.csv(res.est, 
          file = here("4_res",
                      "coefficient-estimates-pH5.csv"),
          row.names = FALSE
)
## write metadata
cat("meta-data for coefficeint-estimates.csv",
    file = here("4_res", "coefficient-estimates-metadata.txt"),
    sep = "\n")
cat(c("Fitting Lotka-Volterra coefficients K and alpha through linear regression (assuming day 21 populations are at equilibrium",
      "We assume the error is normally distributed - this seems close enough to true.",
      "",
      "spec is the focal species",
      "name is the coefficient name. In the cases where name is a species name, it's an alpha term, and the species named is the competing species",
      "est is the estimate FOR LOTKA VOLTERRA MODEL. So the K is in units of individuals, and the other terms are the ALPHAs, which are the coefficient estimates times negative 1.",
      "se is the standard error from the lienar regression"),
    file = here("4_res", "coefficient-estimates-pH5-metadata.txt"),
    sep = "\n",
    append=T)
```

<!-- #### Visualizing for talk -->

<!-- ```{r} -->
<!-- library(scales) -->
<!-- # res.heatmap = matrix(-999, nrow = length(spec.vec), -->
<!-- #                      ncol = length(spec.vec)) -->
<!-- # colnames(res.heatmap)=spec.vec -->
<!-- # rownames(res.heatmap)=spec.vec -->
<!-- #  -->
<!-- # for(cur.spec in unique(res.est$spec)){ -->
<!-- #   res.est.use = res.est[res.est$spec == cur.spec & res.est$name!="K",] -->
<!-- #   res.heatmap[cur.spec,res.est.use$name] = res.est.use$est -->
<!-- # } -->
<!-- # diag(res.heatmap) = NA -->

<!-- res.est$sign = sign(res.est$est) -->
<!-- # res.est$est.sc = sign(res.est$est)*log(abs(res.est$est)) -->

<!-- ggplot(res.est %>% filter(name != "K"), aes(x = name, y = spec)) + -->
<!--   geom_tile(aes(fill = sign))+ -->
<!--   scale_fill_gradient2(low = muted("blue"), -->
<!--                        high = muted("red")) -->

<!-- temp = res.est %>% filter(name != "K") -->
<!-- range(temp$est) -->


<!-- ``` -->


<!-- ```{r} -->
<!-- ## quick thought: scale by carrying capacity -->
<!-- res.sc = res.est -->
<!-- for(cur.name in unique(res.sc$spec)){ -->
<!--   res.sc[res.sc$name==cur.name, "est"] =  -->
<!--     res.sc[res.sc$name==cur.name, "est"] *  -->
<!--     res.sc$est[res.sc$spec == cur.name & res.sc$name == "K"] -->
<!-- } -->

<!-- res.sc$est.sc = sign(res.sc$est)*log(abs(res.sc$est)) -->

<!-- ggplot(res.sc %>% filter(name != "K"), aes(x = name, y = spec)) + -->
<!--   geom_tile(aes(fill = est.sc))+ -->
<!--   scale_fill_gradient2(low = muted("blue"), -->
<!--                        high = muted("red")) -->

<!-- ``` -->


## Comparing to community data

### restructure data

```{r}
raw.com = raw %>% 
  filter(cond == "community") %>% 
  filter(day == 21) %>% 
  filter(pH == 5)

nrep = max(raw.com$rep)
dat.com = data.frame(BC9 = rep(-99, nrep),
                     BC10 = rep(-99, nrep),
                     JB5 = rep(-99, nrep),
                     JB7 = rep(-99, nrep),
                     X135E = rep(-99, nrep),
                     JBC = rep(-99, nrep),
                     JB370 = rep(-99, nrep),
                     rep = 1:nrep
)


## pairs
raw.com$spec[raw.com$spec=="135E"] = "X135E"
spec.vec = as.character(unique(raw.com$spec))

for(cur.spec in spec.vec){
  #get cfus of current species
  dat.cur = raw.com %>% 
    filter(spec == cur.spec) 
  dat.com[dat.cur$rep,cur.spec] = dat.cur$cfus
}
## add NAs
dat.com[dat.com==-99]=NA


write.csv(dat.com, 
          file = here("2_data_wrangling","matrix-form-comdat.csv"),
          row.names = FALSE
)
```

### predicting

```{r}
# read in our community data (e.g. what we saved last chunk)
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH5.csv"))
dat.com = na.omit(dat.com)
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:(length(spec.vecfit))){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}
dat.pred$ph = 5

write.csv(dat.pred,
          here("4_res","predictions-from-pH5.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 5 predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

So our predicted community not only doesn't match our actual community very well, it also doesn't really match possible realities very well. We have a lot of negative numbers.

### Visualizing

```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 5 predictions"
dat.gg = dat.plot

dat.plot = data.frame(est = apply(dat.com,2, median))
dat.plot$spec = colnames(dat.com)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "Actual community"
dat.gg = rbind(dat.gg, dat.plot)

ggplot(data = dat.gg, aes(fill = spec, x = scenario, y = rel))+
  geom_col()+
  ylab("relative abundance")+
  theme.mine

```


# pH 7

Now that we can fit Lotka Volterra with regression models, let's try again, but with pH 7.

## quick sanity check for ks

```{r}
dat.orig %>%  
  filter(cond == "alone") %>%  
  filter(day == 21) %>% 
  filter(pH ==  7) %>%
  # View() %>% 
  group_by(spec) %>% 
  summarize(cfus = median(cfus))
```


## Restructuring the data

```{r}
#make empty data frame
#We want to store cfus for each species, 
dat.mat7 = setNames(data.frame(matrix(ncol = 2*length(unique(raw$spec))+2, nrow = 0)),
                    c(as.character(unique(raw$spec)), "cond", "rep",paste0("pres.",c(as.character(unique(raw$spec)))))
)
raw.use = raw %>% 
  filter(day == 21) %>% 
  filter(pH == 7)
#handle the alones
for(cur.spec in unique(raw.use$spec)){
  print(cur.spec)
  dat.cur = raw.use %>% 
    filter(spec == cur.spec) %>% 
    filter(cond == "alone")
  df.fill=as.data.frame(matrix(0, 
                               nrow=nrow(dat.cur),
                               ncol=ncol(dat.mat7)))
  names(df.fill) = names(dat.mat7)
  df.fill[,cur.spec]=dat.cur$cfus
  df.fill[,"rep"]=dat.cur$rep
  df.fill[,"cond"]="alone"
  df.fill[,paste0("pres.",cur.spec)] = T
  dat.mat7 = rbind(dat.mat7, df.fill)
}

## pairs
spec.vec = as.character(unique(raw.use$spec))

# Process all pairwise interaction experiments
for(i.spec in 1:(length(spec.vec)-1)){ #focal species
  cur.spec = spec.vec[i.spec]
  for(j.spec in (i.spec+1):length(spec.vec)){
    other.spec = spec.vec[j.spec]
    #get cfus of current species
    dat.cur = raw.use %>% 
      filter(spec == cur.spec) %>% 
      filter(cond == other.spec)
    #get cfus of other species
    dat.other = raw.use %>% 
      filter(spec == other.spec) %>% 
      filter(cond == cur.spec)
    #The replicates might not be lined up. Make it so.
    dat.cur = dat.cur[dat.cur$rep %in% dat.other$rep,]
    dat.other = dat.other[dat.other$rep %in% dat.cur$rep,]
    dat.cur=dat.cur[order(dat.cur$rep),]
    dat.other=dat.other[order(dat.other$rep),]
    
    ## Sanity checking to make sure everything is lining up.
    if(nrow(dat.cur) != nrow(dat.other)){
      stop("dimensions not matching up. investigate")
    }
    if(any(dat.cur$rep != dat.other$rep)){
      stop("replicates not matching up. investigate")
    }
    ## if all is working, combine the pieces into a data frame for 
    ##   the current species pair, then stitch to the overall data frame.
    df.fill=as.data.frame(matrix(0,
                                 nrow=nrow(dat.cur),
                                 ncol=ncol(dat.mat7)))
    names(df.fill) = names(dat.mat7)
    df.fill[ , cur.spec] = dat.cur$cfus
    df.fill[ , other.spec] = dat.other$cfus
    df.fill[,"rep"]=dat.cur$rep
    df.fill[,"cond"]="paired-comp"
    df.fill[,paste0("pres.",cur.spec)] = T
    df.fill[,paste0("pres.",other.spec)] = T
    dat.mat7 = rbind(dat.mat7, df.fill)
  }
}
dat.mat7$day = 21
dat.mat7$pH = 7
names(dat.mat7)[names(dat.mat7)=="pres.135E"]="pres.X135E"

write.csv(dat.mat7, 
          file = here("2_data_wrangling","matrix-form-pH7.csv"),
          row.names = FALSE
)
```

## Fit the model

```{r}
dat.fit = read.csv(file = here("2_data_wrangling","matrix-form-pH7.csv"))
res.est = NULL
spec.vecfit = unique(raw$spec)
spec.vecfit[spec.vecfit=="135E"] = "X135E"
for(i.spec in 1:length(spec.vec)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  
  ## calculate K
  dat.k = dat.orig 
  dat.k$spec[dat.k$spec=="135E"]="X135E"
  dat.k = dat.k %>% 
    filter(day==21) %>% 
    filter(spec==cur.spec) %>% 
    filter(cond=="alone") %>% 
    filter(pH == 7)
  out.k = lm(cfus ~ 1, data = dat.k )
  k.cur = out.k$coefficients[[1]]
  
  ## modify the data to ensure we're accounting for K
  ind.use = dat.fit[,paste0("pres.",cur.spec)]==1
  dat.cur = dat.fit[ind.use,]
  dat.cur[,cur.spec]=dat.cur[,cur.spec]-k.cur
  #generate formula automatically
  # Note that we are fit a zero-intercept model, as we have already subtracted out K.
  #
  form = paste0(cur.spec," ~ -1 + ", paste(spec.vecfit[-i.spec], collapse = " + "))
  out.cur = lm(formula(form),
               data = dat.cur)
  est = coefficients(out.cur)
  #sometimes we're getting NAs for se
  #and this doesn't even show up in coef(summary())
  # so we have to do something a little fiddly.
  se = est*NA
  coef.temp = coef(summary(out.cur))[,2]
  se[names(coef.temp)] = coef.temp
  cur.df = data.frame(est = c(coefficients(out.k), est),
                      se = c(coef(summary(out.k))[,2],se))
  #switch to alphas (for everything but Ks, which are the first entry) by multiplying by -1
  cur.df$est[-1]=-cur.df$est[-1]
  cur.df$spec = cur.spec
  cur.df$name = rownames(cur.df)
  cur.df$pH = 7
  rownames(cur.df)=NULL
  cur.df$name[1] = "K"
  #reorder
  cur.df=cur.df[,c("spec","name","est","se", "pH")]
  res.est = rbind(res.est, cur.df)
}

write.csv(res.est, 
          file = here("4_res",
                      "coefficient-estimates-pH7.csv"),
          row.names = FALSE
)
## write metadata
cat("meta-data for coefficeint-estimates.csv",
    file = here("4_res", "coefficient-estimates-pH7-metadata.txt"),
    sep = "\n")
cat(c("Fitting Lotka-Volterra coefficients K and alpha through linear regression (assuming day 21 populations are at equilibrium",
      "As before, but now we are doing pH7 data",
      "We assume the error is normally distributed - this seems close enough to true.",
      "",
      "spec is the focal species",
      "name is the coefficient name. In the cases where name is a species name, it's an alpha term, and the species named is the competing species",
      "est is the estimate FOR LOTKA VOLTERRA MODEL. So the K is in units of individuals, and the other terms are the ALPHAs, which are the coefficient estimates times negative 1.",
      "se is the standard error from the lienar regression"),
    file = here("4_res", "coefficient-estimates-pH7-metadata.txt"),
    sep = "\n",
    append=T)
```

## Comparing to community data

### restructure data

We already did this for the pH5 predictions, and we're using the same community data. We can just read in `matrix-form-comdat.csv`.

```{r}
dat.com = read.csv(file = here("2_data_wrangling","matrix-form-comdat.csv")
)

```

### predicting

Note that we have no estimate for the effect of 135E on JBC since it never survives, BUT we don't have it in the final community. I'm converting all estimates of interactions coming from X135E to 0 in the calculations to avoid NA propogation.

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH7.csv"))
#make a data fram to store predictions - easiest way is to grab existing community data frame and empty it.
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  # (using some transformations (the `t()` function) to make the right pieces line
  # up)
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 7
write.csv(dat.pred,
          here("4_res","predictions-from-pH7.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 7 predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

### Visualizing

Adding to our existing set of predictions

```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 7 predictions"
dat.gg = rbind(dat.gg, dat.plot)

ggplot(data = dat.gg, aes(fill = spec, x = scenario, y = rel))+
  geom_col()+
  ylab("relative abundance")+
  theme.mine

```


# Other predictions

pH 7 has better correspondence to our actual community, but it's far from correct. Brooke has some hypotheses on this.

##  JBC coefficient @ pH 7

What if only JBC had any effects on other species?

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH7.csv"))
## turn anything that's not a K or from JBC to 0
dat.coefs[!dat.coefs$name %in% c("K","JBC"), "est"]=0
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 7

write.csv(dat.pred,
          here("4_res","predictions-onlyJBC-pH7.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 7 only-JBC predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

Add to our quick visualization dataframe
```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 7 only-JBC predictions"
dat.gg = rbind(dat.gg, dat.plot)
```


##  JBC + 135E @ pH 5

UPDATE: THIS SCENARIO IS DECEPTIVE. Leaving it here for now, so that we have it as a reference.But note that since 135E abundance is 0 in allr replicates of the full community, allowing 135E to "have an effect" means nothing - its interaction coefficients will be multiplied by 0 abundance.

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH5.csv"))
## turn anything that's not a K or from JBC to 0
dat.coefs[!dat.coefs$name %in% c("K","JBC", "X135E"), "est"]=0
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 5

write.csv(dat.pred,
          here("4_res","predictions-onlyJBC-135E-pH5.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 5 only-JBC+135E predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

Add to our quick visualization dataframe
```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 5 only-JBC+135E predictions"
dat.gg = rbind(dat.gg, dat.plot)
```

# MSE 

```{r}
real = dat.gg %>% 
  filter(scenario == "Actual community")

print("ph 5 all MSE")
pred.cur = dat.gg %>% 
  filter(scenario == "ph 5 predictions")
mean((real$est-pred.cur$est)^2)

print("ph 7 all MSE")
pred.cur = dat.gg %>% 
  filter(scenario == "ph 7 predictions")
mean((real$est-pred.cur$est)^2)

print("ph 7 one effector")
pred.cur = dat.gg %>% 
  filter(scenario == "ph 7 only-JBC predictions")
mean((real$est-pred.cur$est)^2)

print("ph 5 two effectors")
pred.cur = dat.gg %>% 
  filter(scenario == "ph 5 only-JBC+135E predictions")
mean((real$est-pred.cur$est)^2)


```


# Final visualization

```{r}
ggplot(data = dat.gg, aes(fill = spec, x = scenario, y = rel))+
  geom_col()+
  ylab("relative abundance")+
  theme.mine +
  coord_flip()
```

# Updated checking

From Brooke, 2/18/23: *I poked around your modeling code to try asking whether ANY taxon capable of deacidifying the media could pair with JBC in the pH 5-based model to get the same results as the ph5 2-effector scenario (JBC, JB370, and BC10 are all deacidifiers, so I tried JBC alone @ ph5, JBC+JB370, and JBC+BC10).*

To address this, I'll add in the 3 new scenarios:

## JBC @ pH 5


```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH5.csv"))
## turn anything that's not a K or from JBC to 0
dat.coefs[!dat.coefs$name %in% c("K","JBC"), "est"]=0
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 5

write.csv(dat.pred,
          here("4_res","predictions-onlyJBC-pH5.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 5 only-JBC predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

Add to our quick visualization dataframe
```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 5 only-JBC predictions"
dat.gg = rbind(dat.gg, dat.plot)
```



## JBC + JB370 @ pH 5

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH5.csv"))
## turn anything that's not a K or from JBC to 0
dat.coefs[!dat.coefs$name %in% c("K","JBC", "JB370"), "est"]=0
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 5

write.csv(dat.pred,
          here("4_res","predictions-onlyJBC-JB370-pH5.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 5 only-JBC+JB370 predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

Add to our quick visualization dataframe
```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 5 only-JBC+JB370 predictions"
dat.gg = rbind(dat.gg, dat.plot)
```



## JBC + BC10 @ pH 5

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH5.csv"))
## turn anything that's not a K or from JBC to 0
dat.coefs[!dat.coefs$name %in% c("K","JBC", "BC10"), "est"]=0
dat.pred = dat.com
dat.pred[,-which(names(dat.com)=="rep")]=0
for(i.spec in 1:length(spec.vecfit)){
  cur.spec = spec.vecfit[i.spec]
  print(cur.spec)
  #some cool manipulating to make it easy to access the right coefficients
  # ending in coefs.vec: a vector of coefficients labeled by name
  coefs.cur = dat.coefs %>% 
    filter(spec == cur.spec)
  coefs.vec = coefs.cur$est
  names(coefs.vec) = coefs.cur$name
  if(cur.spec =="JBC"){
    coefs.vec["X135E"]=0
  }
  x.cur = dat.com[,-which(colnames(dat.com) %in% c(cur.spec, "rep"))]
  #using element-wise multiplication to simplify the coding
  #This may look opaque, but you can confirm that it's doing the right thing with 
  # a test case:
  # test.mat = matrix(1:4, 2,2)
  # t(t(test.mat) * c(1,0))
  pred.cur = coefs.vec["K"] - 
    rowSums(t(t(x.cur[,names(coefs.vec)[-1]]) * (coefs.vec[-1])))
  pred.cur = pmax(0,pred.cur)
  dat.pred[,cur.spec] = pred.cur
}

dat.pred$ph = 5

write.csv(dat.pred,
          here("4_res","predictions-onlyJBC-BC10-pH5.csv"),
          row.names=F
)
dat.pred.sav = dat.pred
dat.pred.sav$scenario = "ph 5 only-JBC+BC10 predictions"
pred.all = rbind(pred.all, dat.pred.sav)
```

Add to our quick visualization dataframe
```{r}
dat.plot = data.frame(est = apply(dat.pred,2, median))
dat.plot$spec = colnames(dat.pred)
dat.plot = dat.plot[-which(dat.plot$spec %in% c("rep","ph")),]
dat.plot$est = pmax(dat.plot$est, 0)
dat.plot$rel = dat.plot$est/sum(dat.plot$est)
dat.plot$scenario = "ph 5 only-JBC+BC10 predictions"
dat.gg = rbind(dat.gg, dat.plot)
```

## Updated Viz

```{r}
ggplot(data = dat.gg, aes(fill = spec, x = scenario, y = rel))+
  geom_col()+
  ylab("relative abundance")+
  theme.mine +
  coord_flip()
```

```{r}
write_csv(pred.all, here("4_res/predictions-from-all-scenarios.csv"))
```

## Updated MSE

Note: doing 2 fiddly bits here. Estimating for each replicate separately, and also dividing by 1000, so that we're looking at MSE of thousands of CFUS. This is identical in theory (lowest MSE is still best), but keeps numbers smaller, improving the practicalities.

```{r}
scaling = 1000
mse.df=NULL

dat.real = dat.com %>%  select(-rep)/scaling

print("ph 5 all MSE")
pred.cur = pred.all %>% 
  filter(scenario == "ph 5 predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 5 predictions",
                                  mse = mse.res))

print("ph 7 all MSE")
pred.cur = pred.all %>% 
  filter(scenario == "ph 7 predictions")  %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 7 predictions",
                                  mse = mse.res))


print("ph 7 JBC")
pred.cur = pred.all %>% 
  filter(scenario == "ph 7 only-JBC predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 7 only-JBC predictions",
                                  mse = mse.res))

print("ph 5 JBC + 135E effectors")
pred.cur = pred.all %>% 
  filter(scenario == "ph 5 only-JBC+135E predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 5 only-JBC+135E predictions",
                                  mse = mse.res))

print("ph 5 JBC")
pred.cur = pred.all %>% 
  filter(scenario == "ph 5 only-JBC predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 5 only-JBC predictions",
                                  mse = mse.res))

print("ph 5 JBC+JB370")
pred.cur = pred.all %>% 
  filter(scenario == "ph 5 only-JBC+JB370 predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 5 only-JBC+JB370 predictions",
                                  mse = mse.res))

print("ph 5 JBC+BC10")
pred.cur = pred.all %>% 
  filter(scenario == "ph 5 only-JBC+BC10 predictions") %>% 
  select(-rep, -ph, -scenario)
pred.cur = pred.cur/scaling
sq.er =(dat.real - pred.cur[,names(dat.real)])^2
(mse.res = mean(as.matrix(sq.er)))
mse.df = rbind(mse.df, data.frame(scenario = "ph 5 only-JBC+BC10 predictions",
                                  mse = mse.res))

```

## MSE Viz

Note that we're using 1000s of CFUs as our unit of measure -- the relative positioning of these scenarios is exactly correct, but the orders of magnitude on the MSE axis are lower than you would get if you used 1 individual as your unit of measure.

```{r}
ggplot(mse.df, aes(x = fct_rev(fct_reorder(scenario, mse)), y = mse))+
  geom_col()+
  scale_y_log10()+
  xlab("Scenario")+
  ylab("Mean Squared Error: lowest = most realistic model")+
  coord_flip()
```


# Quick visual check of pH 7 JBC-only

We notice that the pH 7 predictions are almost the same if we only include JBC. This would make sense only if the overwhelming majority of interactions come from JBC (Penicillium). Remember that the total effect of an interaction is the interaction coefficient times the population size of the source of interaction. Here we plot this term (as an absolute value, on a log scale).

```{r}
dat.com=read.csv(here("2_data_wrangling","matrix-form-comdat.csv"))
dat.com=na.omit(dat.com)
# read in our fitted coeffients
dat.coefs = read.csv(here("4_res",
                          "coefficient-estimates-pH7.csv"))

dat.commed = apply(dat.com, 2, median)
dat.temp = dat.coefs %>% 
  filter(name != "K")
dat.temp$eff = dat.temp$est * dat.commed[dat.temp$name]
dat.temp$effab=abs(dat.temp$eff)
# 
# ggplot(dat.temp, aes(x = name, y = est))+
#   geom_point()+
#   scale_y_log10()
# ggplot(dat.temp, aes(x = name, y = eff, col=spec))+
#   geom_line(aes(group=spec))+
#   geom_point()

ggplot(dat.temp, aes(x = name, y = effab, col=spec))+
  geom_line(aes(group=spec))+
  geom_point()+
  scale_y_log10()+theme.mine+
  ylab("Absolute effect of interaction")

```

We see by far the strongest estimated interactions in the pH 7 data are expected to come from JBC, so cutting out all other interactions should not have any effect.

# Which interactions change

This is attempt 2, which is excluding the interaction terms for species which are at 0 density in pH 5

Note: In addition to identifying the significant changes, we identify (a) the original sign of the ALPHA (negative of coefficient estimate) (b) the direction of change of THE ALPHA, and the change in the magnitude of the alpha.

```{r}
dat.7 = read.csv(here("2_data_wrangling",
                      "matrix-form-pH7.csv"))
dat.5 = read.csv(here("2_data_wrangling",
                      "matrix-form.csv"))
dat.full = rbind(dat.7, dat.5)
dat.full$pH=as.character(dat.full$pH)
```

```{r}
findings = list()
sigfind = NULL
```


## BC9
```{r}
dat.cur = dat.full[dat.full$pres.BC9==1,]
out = lm(BC9 ~ BC10*pH + JB5*pH + JB7 + X135E*pH + JBC*pH + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]
findings$BC9 = list(all = Anova(out),
                    sigint = temp,
                    meta = "Insufficient variation in JB7 at pH5. Excluding JB7:pH")
#no terms mattered
```

## BC10
```{r}
dat.cur = dat.full[dat.full$pres.BC10==1,]
out = lm(BC10 ~ BC9*pH + JB5*pH + JB7*pH + X135E*pH + JBC*pH + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]

findings$BC10 = list(all = Anova(out),
                     sigint = temp,
                     meta = "All terms included")
#making piece to add to to overall data frame
sigfind.cur = as.data.frame(temp)

## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig - coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "BC10"
sigfind = rbind(sigfind, sigfind.cur)

```

## JB5
```{r}
dat.cur = dat.full[dat.full$pres.JB5==1,]
out = lm(JB5 ~ BC9*pH + BC10*pH + JB7*pH + X135E*pH + JBC*pH + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]
#adding to overall data frame
sigfind.cur =as.data.frame(temp) 
## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig -coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "JB5"
sigfind = rbind(sigfind, sigfind.cur)
```

## JB7
```{r}
dat.cur = dat.full[dat.full$pres.JB7==1,]
out = lm(JB7 ~ BC9*pH + BC10*pH + JB5*pH + X135E*pH + JBC*pH + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]

findings$JB7 = list(all = Anova(out),
                    sigint = temp,
                    meta = "All terms included")
#adding to overall data frame
sigfind.cur =as.data.frame(temp) 
## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig -coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "JB7"
sigfind = rbind(sigfind, sigfind.cur)
```

## X135E
```{r}
dat.cur = dat.full[dat.full$pres.X135E==1,]
out = lm(X135E ~ BC9*pH + BC10*pH + JB5*pH + JB7*pH + JBC*pH + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]
findings$X135E = list(all = Anova(out),
                      sigint = temp,
                      meta = "All terms included")
#adding to overall data frame
sigfind.cur =as.data.frame(temp) 
## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig -coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "X135E"

sigfind = rbind(sigfind, sigfind.cur)
```

## JBC
```{r}
dat.cur = dat.full[dat.full$pres.JBC==1,]
# View(dat.cur)
out = lm(JBC ~ BC9*pH + BC10*pH + JB5 + JB7*pH + X135E + JB370*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]
findings$JBC = list(all = Anova(out),
                    sigint = temp,
                    meta = "Insufficient JB5 and X135E at pH 5 - both JB5:pH and X135E:pH were removed.")
#adding to overall data frame
sigfind.cur = as.data.frame(temp) 
## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig -coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "JBC"
sigfind = rbind(sigfind, sigfind.cur)
```

## JB370
```{r}
dat.cur = dat.full[dat.full$pres.JB370==1,]
out = lm(JB370 ~ BC9*pH + BC10*pH + JB5*pH + JB7*pH + X135E*pH + JBC*pH,
         data = dat.cur)
summary(out)
temp = Anova(out)
temp = temp[grep(':',rownames(temp)),]
temp = temp[temp$`Pr(>F)`<.1,]
findings$JB370 = list(all = Anova(out),
                      sigint = temp,
                      meta = "All terms included")
#adding to overall data frame
sigfind.cur =as.data.frame(temp) 
## calculating the original interaction coefficient sign
names.temp = gsub("pH","",rownames(temp))
names.temp = gsub(":","", names.temp)
coef.orig = -coefficients(out)[names.temp]
## kludgy way of extracting coefficients
## Note that Anova gives rownames for coefficients, while out gives rownames for
##   the coefficient LEVELS, so we need to turn pH into pH7
coef.temp = coefficients(out)[gsub("pH","pH7",rownames(temp))]
coef.new =coef.orig -coef.temp
## calculate change in the sign
sigfind.cur$coef.orig = coef.orig
sigfind.cur$coef.new = coef.new
sigfind.cur$sign.change = -sign(coef.temp)
sigfind.cur$magnitude.change = abs(coef.new/coef.orig)
sigfind.cur$source.species = gsub(":","",
                                  gsub("pH","",rownames(sigfind.cur)))
sigfind.cur$target.species = "JB370"
sigfind = rbind(sigfind, sigfind.cur)
```


## Saving

```{r}
write.csv(sigfind,here("4_res","pH-interaction-estimates.csv"), row.names = FALSE)

saveRDS(findings, file = here("4_res","ph-interactions-list-obj.RDS"))
```

